{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\valin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\valin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0  im feeling rather rotten so im not very ambiti...      0   \n",
      "1          im updating my blog because i feel shitty      0   \n",
      "2  i never make her separate from me because i do...      0   \n",
      "3  i left with my bouquet of red and yellow tulip...      1   \n",
      "4    i was feeling a little vain when i did this one      0   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0        im feeling rather rotten im ambitious right  \n",
      "1                       im updating blog feel shitty  \n",
      "2    never make separate ever want feel like ashamed  \n",
      "3  left bouquet red yellow tulips arm feeling sli...  \n",
      "4                            feeling little vain one  \n"
     ]
    }
   ],
   "source": [
    "#Data Loading and Pre-processing\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"test.csv\")  \n",
    "\n",
    "# Load NLP Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply Preprocessing\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "print(df.head())  # Check cleaned feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           cleaned_text  \\\n",
      "0           im feeling rather rotten im ambitious right   \n",
      "1                          im updating blog feel shitty   \n",
      "2       never make separate ever want feel like ashamed   \n",
      "3     left bouquet red yellow tulips arm feeling sli...   \n",
      "4                               feeling little vain one   \n",
      "...                                                 ...   \n",
      "1995  keep feeling like someone unkind wrong think g...   \n",
      "1996  im feeling little cranky negative doctors appo...   \n",
      "1997  feel useful people gives great feeling achieve...   \n",
      "1998  im feeling comfortable derby feel though start...   \n",
      "1999  feel weird meet w people text like dont talk f...   \n",
      "\n",
      "                                         emotion_scores  \n",
      "0     {'sadness': 0.9988346695899963, 'joy': 0.00021...  \n",
      "1     {'sadness': 0.9988738894462585, 'joy': 0.00022...  \n",
      "2     {'sadness': 0.9990485310554504, 'joy': 0.00017...  \n",
      "3     {'sadness': 0.00031173875322565436, 'joy': 0.9...  \n",
      "4     {'sadness': 0.9988553524017334, 'joy': 0.00020...  \n",
      "...                                                 ...  \n",
      "1995  {'sadness': 0.0006228340789675713, 'joy': 0.00...  \n",
      "1996  {'sadness': 0.00044778751907870173, 'joy': 0.0...  \n",
      "1997  {'sadness': 0.00028890822432003915, 'joy': 0.9...  \n",
      "1998  {'sadness': 0.00029813271248713136, 'joy': 0.9...  \n",
      "1999  {'sadness': 0.002421777928248048, 'joy': 0.001...  \n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load Pre-trained Model for Emotion Detection\n",
    "emotion_model = pipeline(\"text-classification\", model=\"bhadresh-savani/distilbert-base-uncased-emotion\", return_all_scores=True)\n",
    "\n",
    "# Function to Get Emotion Scores\n",
    "def detect_emotions(text):\n",
    "    emotions = emotion_model(text)\n",
    "    emotions = emotions[0]  # Extract from list\n",
    "    scores = {e['label']: e['score'] for e in emotions}\n",
    "    return scores\n",
    "\n",
    "# Apply to Data\n",
    "df['emotion_scores'] = df['cleaned_text'].apply(detect_emotions)\n",
    "\n",
    "print(df[['cleaned_text', 'emotion_scores']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           cleaned_text  \\\n",
      "0           im feeling rather rotten im ambitious right   \n",
      "1                          im updating blog feel shitty   \n",
      "2       never make separate ever want feel like ashamed   \n",
      "3     left bouquet red yellow tulips arm feeling sli...   \n",
      "4                               feeling little vain one   \n",
      "...                                                 ...   \n",
      "1995  keep feeling like someone unkind wrong think g...   \n",
      "1996  im feeling little cranky negative doctors appo...   \n",
      "1997  feel useful people gives great feeling achieve...   \n",
      "1998  im feeling comfortable derby feel though start...   \n",
      "1999  feel weird meet w people text like dont talk f...   \n",
      "\n",
      "                              topics  \n",
      "0                                 []  \n",
      "1                     [blog, shitty]  \n",
      "2                                 []  \n",
      "3              [bouquet, red, tulip]  \n",
      "4                                 []  \n",
      "...                              ...  \n",
      "1995                        [people]  \n",
      "1996           [doctor, appointment]  \n",
      "1997  [people, feeling, achievement]  \n",
      "1998      [derby, feel, step, shell]  \n",
      "1999      [w, people, text, face, w]  \n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_topics(text):\n",
    "    doc = nlp(text)\n",
    "    topics = [token.lemma_ for token in doc if token.pos_ in ['NOUN', 'PROPN']]\n",
    "    return topics\n",
    "\n",
    "df['topics'] = df['cleaned_text'].apply(extract_topics)\n",
    "\n",
    "print(df[['cleaned_text', 'topics']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         emotion_scores emotion_intensity\n",
      "0     {'sadness': 0.9988346695899963, 'joy': 0.00021...              High\n",
      "1     {'sadness': 0.9988738894462585, 'joy': 0.00022...              High\n",
      "2     {'sadness': 0.9990485310554504, 'joy': 0.00017...              High\n",
      "3     {'sadness': 0.00031173875322565436, 'joy': 0.9...              High\n",
      "4     {'sadness': 0.9988553524017334, 'joy': 0.00020...              High\n",
      "...                                                 ...               ...\n",
      "1995  {'sadness': 0.0006228340789675713, 'joy': 0.00...              High\n",
      "1996  {'sadness': 0.00044778751907870173, 'joy': 0.0...              High\n",
      "1997  {'sadness': 0.00028890822432003915, 'joy': 0.9...              High\n",
      "1998  {'sadness': 0.00029813271248713136, 'joy': 0.9...              High\n",
      "1999  {'sadness': 0.002421777928248048, 'joy': 0.001...            Medium\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def emotion_intensity(emotion_scores):\n",
    "    max_emotion = max(emotion_scores, key=emotion_scores.get)  # Get most dominant emotion\n",
    "    max_score = emotion_scores[max_emotion]\n",
    "\n",
    "    if max_score >= 0.7:\n",
    "        return \"High\"\n",
    "    elif 0.4 <= max_score < 0.7:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "df['emotion_intensity'] = df['emotion_scores'].apply(emotion_intensity)\n",
    "\n",
    "print(df[['emotion_scores', 'emotion_intensity']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           cleaned_text  adorescore\n",
      "0           im feeling rather rotten im ambitious right       -0.70\n",
      "1                          im updating blog feel shitty       -0.70\n",
      "2       never make separate ever want feel like ashamed       -0.70\n",
      "3     left bouquet red yellow tulips arm feeling sli...        1.00\n",
      "4                               feeling little vain one       -0.70\n",
      "...                                                 ...         ...\n",
      "1995  keep feeling like someone unkind wrong think g...       -1.00\n",
      "1996  im feeling little cranky negative doctors appo...       -1.00\n",
      "1997  feel useful people gives great feeling achieve...        1.00\n",
      "1998  im feeling comfortable derby feel though start...        1.00\n",
      "1999  feel weird meet w people text like dont talk f...       -0.16\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def calculate_adorescore(emotion_scores):\n",
    "    weights = {'joy': 1.0, 'anger': -1.0, 'sadness': -0.7, 'fear': -0.5, 'love': 0.8, 'surprise': 0.5}\n",
    "    score = sum(weights.get(emotion, 0) * value for emotion, value in emotion_scores.items())\n",
    "    return round(score, 2)\n",
    "\n",
    "df['adorescore'] = df['emotion_scores'].apply(calculate_adorescore)\n",
    "\n",
    "print(df[['cleaned_text', 'adorescore']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           cleaned_text  \\\n",
      "0           im feeling rather rotten im ambitious right   \n",
      "1                          im updating blog feel shitty   \n",
      "2       never make separate ever want feel like ashamed   \n",
      "3     left bouquet red yellow tulips arm feeling sli...   \n",
      "4                               feeling little vain one   \n",
      "...                                                 ...   \n",
      "1995  keep feeling like someone unkind wrong think g...   \n",
      "1996  im feeling little cranky negative doctors appo...   \n",
      "1997  feel useful people gives great feeling achieve...   \n",
      "1998  im feeling comfortable derby feel though start...   \n",
      "1999  feel weird meet w people text like dont talk f...   \n",
      "\n",
      "                emotion_mapping  \n",
      "0     High intensity in sadness  \n",
      "1     High intensity in sadness  \n",
      "2     High intensity in sadness  \n",
      "3         High intensity in joy  \n",
      "4     High intensity in sadness  \n",
      "...                         ...  \n",
      "1995    High intensity in anger  \n",
      "1996    High intensity in anger  \n",
      "1997      High intensity in joy  \n",
      "1998      High intensity in joy  \n",
      "1999   Medium intensity in fear  \n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def map_intensity(row):\n",
    "    return f\"{row['emotion_intensity']} intensity in {max(row['emotion_scores'], key=row['emotion_scores'].get)}\"\n",
    "\n",
    "df['emotion_mapping'] = df.apply(map_intensity, axis=1)\n",
    "\n",
    "print(df[['cleaned_text', 'emotion_mapping']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\valin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       1.00      1.00      1.00       273\n",
      "        fear       1.00      1.00      1.00       235\n",
      "         joy       1.00      1.00      1.00       691\n",
      "        love       1.00      1.00      1.00       169\n",
      "     sadness       1.00      1.00      1.00       573\n",
      "    surprise       1.00      1.00      1.00        59\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load Emotion Detection Model (Same one used before)\n",
    "emotion_model = pipeline(\"text-classification\", model=\"bhadresh-savani/distilbert-base-uncased-emotion\", return_all_scores=True)\n",
    "\n",
    "# Function to Get True Labels\n",
    "def get_true_label(text):\n",
    "    emotions = emotion_model(text)\n",
    "    best_emotion = max(emotions[0], key=lambda x: x['score'])['label']  # Get the highest scoring emotion\n",
    "    return best_emotion\n",
    "\n",
    "# Assign True Labels Using Model\n",
    "df['true_labels'] = df['cleaned_text'].apply(get_true_label)  \n",
    "\n",
    "# Predicted Labels (from our detected emotions)\n",
    "df['predicted_labels'] = df['emotion_scores'].apply(lambda x: max(x, key=x.get))\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(df['true_labels'], df['predicted_labels'])\n",
    "report = classification_report(df['true_labels'], df['predicted_labels'])\n",
    "\n",
    "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [22020]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [22020]\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "import uvicorn\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class FeedbackRequest(BaseModel):\n",
    "    text: str\n",
    "\n",
    "@app.post(\"/analyze/\")\n",
    "def analyze_feedback(request: FeedbackRequest):\n",
    "    text = request.text\n",
    "    cleaned_text = preprocess_text(text)\n",
    "    emotion_scores = detect_emotions(cleaned_text)\n",
    "    topics = extract_topics(cleaned_text)\n",
    "    intensity = emotion_intensity(emotion_scores)\n",
    "    adorescore = calculate_adorescore(emotion_scores)\n",
    "    mapping = f\"{intensity} intensity in {max(emotion_scores, key=emotion_scores.get)}\"\n",
    "\n",
    "    return {\n",
    "        \"feedback\": text,\n",
    "        \"cleaned_feedback\": cleaned_text,\n",
    "        \"emotion_scores\": emotion_scores,\n",
    "        \"emotion_intensity\": intensity,\n",
    "        \"topics\": topics,\n",
    "        \"adorescore\": adorescore,\n",
    "        \"emotion_mapping\": mapping\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
